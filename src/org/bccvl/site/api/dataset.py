from org.bccvl.site.interfaces import IDownloadInfo, IBCCVLMetadata
# had to remove this to avoid circular import because of form hints widgets in interfaces.py
#from org.bccvl.site.content.interfaces import IDataset
from plone.uuid.interfaces import IUUID
from Products.CMFCore.utils import getToolByName
from Products.ZCatalog.interfaces import ICatalogBrain
from plone.app.uuid.utils import uuidToObject
from zope.component import getUtility
from zope.schema.interfaces import IVocabularyFactory


def getdsmetadata(ds):
    # TODO: support brain, obj and uuid string (URI as well?)
    # extract info about files
    if ICatalogBrain.providedBy(ds):
        ds = ds.getObject()
        # TODO: try to use brains only here
        #    url: ds.getURL()
        #    id: ds.UID,
        #    description: ds.Description
    # start with metadata annotation
    md = {
        #'@context': { },
        '@id': IUUID(ds),
        '@type': ds.portal_type,
        'url': ds.absolute_url(),
        'id': IUUID(ds),
        'title': ds.title,
        'description': ds.description,
    }
    md.update(IBCCVLMetadata(ds))
    # add layer titles
    layer_vocab = getUtility(IVocabularyFactory, 'layer_source')(ds)
    for layer in md.get('layers', {}).values():
        if layer.has_key('layer'):
            layer['title'] = layer_vocab.getLayerTitle(layer['layer'])

    dlinfo = IDownloadInfo(ds)
    md.update({
        'mimetype': dlinfo['contenttype'],
        'filename': dlinfo['filename'],
        'file': dlinfo['url'],
    })
    return md


# FIXME: this method is potentially very slow
def getThresholds(datasets, thresholds=None):
    # dataset to get thresholds for
    # thresholds a list of threshold names to return (if None return all)
    if not isinstance(datasets, list):
        datasets = [datasets]
    result = {}  # we have to return per experiment, per dataset/result
    for dataset in datasets:
        dataobj = uuidToObject(dataset)
        if dataobj is None:
            continue
        datamd = IBCCVLMetadata(dataobj)
        if datamd['genre'] in ('DataGenreFP', 'DataGenreFP_ENVLOP'):
            # we have a future projection ... go look for thresholds at SDM result
            sdmuuid = dataobj.__parent__.job_params['species_distribution_models']
            # get sdm result container
            sdmresult = uuidToObject(sdmuuid).__parent__
        elif datamd['genre'] in ['DataGenreCP', 'DataGenreCP_ENVLOP', 'DataGenreSDMModel']:
            # we have a current projection ...
            sdmresult = dataobj.__parent__
        else:
            continue
        # We have the sdm result container ... find thresholds now
        pc = getToolByName(dataobj, 'portal_catalog')
        # find all model eval datasets
        thresholds = {}
        for evalbrain in pc.searchResults(path='/'.join(sdmresult.getPhysicalPath()),
                                          BCCDataGenre='DataGenreSDMEval'):
            evalmd = IBCCVLMetadata(evalbrain.getObject())
            # FIXME: ideally we got only datasets with thresholds back here, but
            #        at the moment DataGenreSDMEval is aso used for graphs (png  files)
            #        generated by the algorithms
            if 'thresholds' not in evalmd:
                continue
            # TODO: merging of thresholds is random here
            thresholds.update(evalmd['thresholds'])
        result[dataset] = thresholds
    return result
